{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C2ST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunsshah/C2ST/blob/main/C2ST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier Based Two Sample Testing\n",
        "In two-sample testing, we want to determine if two selected samples come from the same or different distributions. C2ST aims to use neural network classifiers to help determine this. "
      ],
      "metadata": {
        "id": "Ag9mNKX42d_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process\n",
        "Two samples, $S_P = \\{x_1,...,x_n\\}$ and $S_Q = \\{y_1, ..., y_m\\}$\n",
        "\n",
        "1) Construct our dataset\n",
        "\n",
        "$D = \\{(x_i,0)\\}^n_{i=1} \\cup \\{(y_i,0)\\}^n_{i=1} = \\{z_i,l_i\\}^{2n}_{i=1}$\n",
        "\n",
        "2) Split dataset\n",
        "\n",
        "Shuffle into train-test split\n",
        "\n",
        "3) Train binary classifier\n",
        "\n",
        "4) Return a classification accuracy on $D_{te}$:\n",
        "\n",
        "$\\hat t = \\frac{1}{n_{te}} \\Sigma_{(z_i, l_i) \\in D_{te}} I[I(f(z_i) > \\frac{1}{2}) = l_i]$\n",
        "\n",
        "\n",
        "5) Accept/Reject $H_0$: A significance threshold is written up below where if our c2st statistics is less than it, we accept the null hypothesis, otherwise we reject.\n"
      ],
      "metadata": {
        "id": "o37vZtFQz0c2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use this notebook?\n",
        "I will outline the steps needed to understand and use this notebook to perform classifier two-sample testing on any datasets\n",
        "\n",
        "Below I have outlined a c2st function that takes in both samples, X and Y, along with other parameters that can be edited. \n",
        "\n",
        "For example, here is a classifier two-sample test between a student t-distribution and gaussian distribution:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "student = scale(np.random.standard_t(20, size = 1000)).reshape(-10,10) # X\n",
        "gaussian = scale(np.random.normal(0,1,1000)).reshape(-10,10) # Y\n",
        "\n",
        "c2st(student, gaussian)\n",
        "```\n",
        "The last line will return the c2st score for the two samples. Currently, the default parameter for the machine learning model used as our classifier is a RandomForestClassifier but can be changed as a parameter:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "c2st(student, gaussian, clf=MLPClassifier(activation='tanh', hidden_layer_sizes=(10,10,10), max_iter=600))\n",
        "```\n",
        "Here, you can edit the number of hidden layers, activation functions, etc for our classifier. Here is a [link](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) to the sckit-learn MLPClassifer model for specifics.\n",
        "\n",
        "### Accepting/Rejecting $H_0$ and Power\n",
        "\n",
        "I have created two functions, significance_threshold and power, in order to determine when we accept/reject our null hypothesis. Both of these formulas come straight from Lopez-Paz's paper in the appendix. Here is an example of using the significance_threshold function:\n",
        "\n",
        "\n",
        "```\n",
        "significance_threshold(0.05, 100)\n",
        "```\n",
        "The first parameter is the significance level and the second parameter is the size of our test set when we do the train test split. \n",
        "\n",
        "The power function is similar in nature except it has an additional parameter representing the distance of our c2st score from 0.5 (the null hypothesis). Here is an example of how this can be calculated using our student vs gaussian example:\n",
        "\n",
        "\n",
        "```\n",
        "c2stScore = c2st(student, gaussian)\n",
        "epsilon = c2stScore - 0.5\n",
        "power(0.05, 1000, epsilon)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3nDPeQgccKs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union, Tuple\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from __future__ import annotations\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "from numpy.random import default_rng\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import __version__ as sklversion\n",
        "import time\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import scipy\n",
        "import math\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "FIXEDSEED = 1309\n",
        "\n",
        "\n",
        "NDIM = 10\n",
        "max_nsamples = 8096\n",
        "sample_sizes = [ 2**it for it in range(7,12)]\n",
        "sample_sizes.append(max_nsamples)\n",
        "RNG = default_rng(FIXEDSEED)\n",
        "print(sample_sizes)"
      ],
      "metadata": {
        "id": "KEa5eWrN2ioH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f36cfe-d95c-4ab9-ba6c-5697b4bef02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[128, 256, 512, 1024, 2048, 8096]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def c2st(\n",
        "    X: np.ndarray,\n",
        "    Y: np.ndarray,\n",
        "    scoring: str = \"balanced_accuracy\",\n",
        "    z_score: bool = True,\n",
        "    noise_scale: float = None,\n",
        "    verbosity: int = 0,\n",
        "    clf=RandomForestClassifier(random_state=1),\n",
        "    cv=KFold(n_splits=10, shuffle=True, random_state=1),\n",
        "    return_scores: bool = False,\n",
        "    nan_drop: bool = False,\n",
        ") -> Union[float, Tuple[float, np.ndarray]]:\n",
        "\n",
        "  \"\"\"\n",
        "   Args:\n",
        "        X: Samples from one distribution, shape (n_samples_X, n_features)\n",
        "        Y: Samples from another distribution, shape (n_samples_Y, n_features)\n",
        "        scoring: a classifier scoring metric, anything that\n",
        "            sklearn.model_selection.cross_val_score(scoring=...) accepts\n",
        "        z_score: Z-scoring using X\n",
        "        noise_scale: If passed, will add Gaussian noise with std noise_scale to\n",
        "            samples of X and of Y\n",
        "        verbosity: control the verbosity of\n",
        "            sklearn.model_selection.cross_val_score\n",
        "        clf: a scikit-learn classifier class instance\n",
        "        cv: cross-validation class instance with sklearn API, e.g.\n",
        "            sklearn.model_selection.KFold\n",
        "        return_scores: Return 1d array of CV scores in addition to their mean\n",
        "        nan_drop: Filter NaNs from CV scores and at least return the mean of\n",
        "            the values left in scores.\n",
        "  \"\"\"\n",
        "    \n",
        "    # if z_score:\n",
        "    #     X_mean = np.mean(X, axis=0)\n",
        "    #     X_std = np.std(X, axis=0)\n",
        "    #     X = (X - X_mean) / X_std\n",
        "    #     Y = (Y - X_mean) / X_std\n",
        "\n",
        "  # if noise_scale is not None:\n",
        "  #       X += noise_scale * np.random.randn(*X.shape)\n",
        "  #       Y += noise_scale * np.random.randn(*Y.shape)\n",
        "\n",
        "    # prepare data\n",
        "  data = np.concatenate((X, Y))\n",
        "    # labels\n",
        "  target = np.concatenate((np.zeros((X.shape[0],)), np.ones((Y.shape[0],))))\n",
        "\n",
        "  scores = cross_val_score(\n",
        "        clf, data, target, cv=cv, scoring=scoring, verbose=verbosity\n",
        "  )\n",
        "\n",
        "  if nan_drop:\n",
        "      isnan = np.isnan(scores)\n",
        "      if isnan.any():\n",
        "          scores = scores[~isnan]\n",
        "      if len(scores) == 0:\n",
        "          warnings.warn(\"Only NaN scores, return NaN\")\n",
        "          if return_scores:\n",
        "              return np.nan, np.array([np.nan] * len(isnan))\n",
        "          else:\n",
        "              return np.nan\n",
        "  mean_scores = scores.mean()\n",
        "  return mean_scores, scores\n",
        "  # if return_scores:\n",
        "  #     return scores\n",
        "  # else:\n",
        "  #     return mean_scores, scores"
      ],
      "metadata": {
        "id": "CnU6RhqPc1RW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu1, sigma1 = 0, 0.1 # mean and standard deviation\n",
        "mu2, sigma2 = 0, 0.3\n",
        "s1 = np.random.normal(mu1, sigma1, 100).reshape(-1,1)\n",
        "s2 = np.random.normal(mu2, sigma2, 100).reshape(-1,1)\n",
        "c2st(s1,s2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIl_Zi2zfzMB",
        "outputId": "df1386d6-1b69-4560-ccae-bc1bbc4f4987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6672896547896549,\n",
              " array([0.49494949, 0.77083333, 0.45604396, 0.70707071, 0.73076923,\n",
              "        0.57142857, 0.77083333, 0.8989899 , 0.59340659, 0.67857143]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c2st(s1,s2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzYceCuUf-1s",
        "outputId": "62891b8a-57df-45e3-cae9-0d8773c7a7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9661999200900804"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def significance_threshold(\n",
        "    # significance threshold\n",
        "    # we accept the null hypothesis if we are under this threshold, reject when\n",
        "    # above this threshold\n",
        "    a: float,\n",
        "    nte: int,\n",
        "\n",
        "  ) -> float:\n",
        "  \"\"\"\n",
        "  Args: \n",
        "    a: significance level\n",
        "    nte: size of test set in D\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  z = 0.5 + (scipy.stats.norm.ppf(1-a)) / math.sqrt(4 * nte)\n",
        "  return z"
      ],
      "metadata": {
        "id": "oAIIlEIFoRTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def power(\n",
        "    # returns the probability of making a type II error\n",
        "    a: float,\n",
        "    nte: int,\n",
        "    epsilon: float # epsilon is the different from the acheived c2st score and 0.5\n",
        "  ) -> float:\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    a: significance level\n",
        "    nte: size of test set in D\n",
        "    epsilon: difference between c2st score and 0.5\n",
        "  \"\"\"\n",
        "\n",
        "  p = scipy.stats.norm.cdf( ( (scipy.stats.norm.ppf(1-a) / 2) - epsilon * math.sqrt(nte) ) / math.sqrt((1/4) - epsilon**2) )\n",
        "  return p "
      ],
      "metadata": {
        "id": "KwmBdMGM78fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "significance_threshold(0.05, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC6cMg_1p_zq",
        "outputId": "e8900c0f-e042-4516-eb99-20e04379bc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5822426813475736"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "power(0.05, 100, 0.08)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVRLm_vI9FJr",
        "outputId": "0e7af88f-2968-4871-f784-58a9a762b365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.518121309052312"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test to repeatedly accept/reject the null hypothesis\n",
        "num_accepted = 0\n",
        "num_rejected = 0\n",
        "thresh = significance_threshold(0.05, 1000)\n",
        "for i in range(100):\n",
        "  mu1, sigma1 = 0, 0.1 # mean and standard deviation\n",
        "  mu2, sigma2 = 0, 0.1\n",
        "  s1 = np.random.normal(mu1, sigma1, 1000).reshape(-10,10)\n",
        "  s2 = np.random.normal(mu2, sigma2, 1000).reshape(-10,10)\n",
        "  c2stScore = c2st(s1, s2)\n",
        "  if c2stScore < thresh:\n",
        "    num_accepted += 1\n",
        "  else:\n",
        "    num_rejected += 1\n",
        "print(num_rejected / 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "S0Zq6qlP2xmu",
        "outputId": "21c305c1-3eee-4056-b7f0-60e50efaf7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1ea2a84b5afd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mc2stScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc2st\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mc2stScore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnum_accepted\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# student t distribution vs gaussian\n",
        "student = scale(np.random.standard_t(20, size = 1000)).reshape(-10,10)\n",
        "gaussian = scale(np.random.normal(0,1,1000)).reshape(-10,10)\n",
        "\n",
        "c2stScore = c2st(student, gaussian)\n",
        "epsilon = c2stScore - 0.5\n",
        "c2stScore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm_jqKbBqE3u",
        "outputId": "575f8677-b691-4bd5-fbfe-82b4538d2865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5017250267418527"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# student t distribution vs gaussian power\n",
        "type2Error = []\n",
        "dOfF = list(range(1,20))\n",
        "for i in dOfF:\n",
        "  student = scale(np.random.standard_t(i, size = 1000)).reshape(-10,10)\n",
        "  gaussian = scale(np.random.normal(0,1,1000)).reshape(-10,10)\n",
        "  c2stScore = c2st(student, gaussian)\n",
        "  epsilon = abs(c2stScore - 0.5)\n",
        "  type2Error.append(power(0.05, 1000, epsilon))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnilEAli4wdC",
        "outputId": "279acde7-14da-4a81-a965-7cafb18ed4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qD8sgO4f7Wru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c2st(X=s1,Y=s2, clf=MLPClassifier(activation='tanh', hidden_layer_sizes=(10,10,10), max_iter=600))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIb4Eu2kA3lR",
        "outputId": "c6799358-d961-4150-c110-031d488bab77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7981073450113698"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fYsuvCyNY7_z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}